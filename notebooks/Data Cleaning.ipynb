{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project structure (educational style)\n",
    "PROJECT_ROOT = Path(\".\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"leapgestrecog\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "CLEAN_DIR = DATA_DIR / \"clean\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì• Downloading dataset...\")\n",
    "path = kagglehub.dataset_download(\"gti-upm/leapgestrecog\")\n",
    "print(\"Downloaded to:\", path)\n",
    "\n",
    "# Dataset usually contains 'leapGestRecog'\n",
    "if os.path.isdir(os.path.join(path, \"leapGestRecog\")):\n",
    "    src = os.path.join(path, \"leapGestRecog\")\n",
    "else:\n",
    "    src = path\n",
    "\n",
    "print(\"Using source:\", src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy raw data once\n",
    "if not any(RAW_DIR.iterdir()):\n",
    "    shutil.copytree(src, RAW_DIR, dirs_exist_ok=True)\n",
    "    print(\"‚úÖ Raw data copied\")\n",
    "\n",
    "# Create clean data copy\n",
    "if not CLEAN_DIR.exists():\n",
    "    shutil.copytree(RAW_DIR, CLEAN_DIR)\n",
    "    print(\"‚úÖ Clean data folder created\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Clean data already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corrupted(folder: Path):\n",
    "    \"\"\"Remove images that cannot be read.\"\"\"\n",
    "    print(\"\\nüßπ Removing corrupted images...\")\n",
    "    for cls in tqdm(os.listdir(folder)):\n",
    "        cls_path = folder / cls\n",
    "        if not cls_path.is_dir():\n",
    "            continue\n",
    "        for file in os.listdir(cls_path):\n",
    "            img_path = cls_path / file\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is None:\n",
    "                    img_path.unlink(missing_ok=True)\n",
    "            except:\n",
    "                img_path.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_format(folder: Path, size=(224, 224)):\n",
    "    \"\"\"Convert images to RGB and resize.\"\"\"\n",
    "    print(\"\\nüé® Standardizing images...\")\n",
    "    for cls in tqdm(os.listdir(folder)):\n",
    "        cls_path = folder / cls\n",
    "        if not cls_path.is_dir():\n",
    "            continue\n",
    "        for file in os.listdir(cls_path):\n",
    "            img_path = cls_path / file\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img = img.resize(size)\n",
    "                img.save(img_path)\n",
    "            except:\n",
    "                img_path.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(folder: Path):\n",
    "    \"\"\"Remove duplicate images using MD5 hash.\"\"\"\n",
    "    print(\"\\nüóëÔ∏è Removing duplicates...\")\n",
    "    seen = set()\n",
    "    for cls in tqdm(os.listdir(folder)):\n",
    "        cls_path = folder / cls\n",
    "        if not cls_path.is_dir():\n",
    "            continue\n",
    "        for file in os.listdir(cls_path):\n",
    "            img_path = cls_path / file\n",
    "            if img_path.is_dir():\n",
    "                continue\n",
    "            with open(img_path, \"rb\") as f:\n",
    "                h = hashlib.md5(f.read()).hexdigest()\n",
    "            if h in seen:\n",
    "                img_path.unlink(missing_ok=True)\n",
    "            else:\n",
    "                seen.add(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(folder: Path):\n",
    "    \"\"\"Apply denoising filter.\"\"\"\n",
    "    print(\"\\n‚ú® Denoising images...\")\n",
    "    for cls in tqdm(os.listdir(folder)):\n",
    "        cls_path = folder / cls\n",
    "        if not cls_path.is_dir():\n",
    "            continue\n",
    "        for file in os.listdir(cls_path):\n",
    "            img_path = cls_path / file\n",
    "            if img_path.is_dir():\n",
    "                continue\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "                cv2.imwrite(str(img_path), img)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_balance(folder: Path):\n",
    "    \"\"\"Show number of images per class.\"\"\"\n",
    "    print(\"\\nüìä Class Balance:\")\n",
    "    for cls in sorted(os.listdir(folder)):\n",
    "        cls_path = folder / cls\n",
    "        if cls_path.is_dir():\n",
    "            print(f\"{cls}: {len(os.listdir(cls_path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cleaning pipeline\n",
    "remove_corrupted(CLEAN_DIR)\n",
    "fix_format(CLEAN_DIR, IMG_SIZE)\n",
    "remove_duplicates(CLEAN_DIR)\n",
    "denoise(CLEAN_DIR)\n",
    "show_balance(CLEAN_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 39466,
     "sourceId": 61155,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
